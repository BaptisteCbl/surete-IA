

* Installation from fresh environment.

#+begin_src bash
conda env create --file slim.yml
#+end_src

#+begin_src bash
conda activate RobustSlim
#+end_src

#+begin_src bash
pip install -e .
#+end_src

* Running the scripts

Running the training from quicktest/
#+begin_src bash
python src/training.py  --flagfile=config_files/training.cfg
#+end_src

Running the evaluation
#+begin_src bash
python src/evaluation.py  --flagfile=config_files/evaluation.cfg
#+end_src

** The configuration files

We use the /abseil/ library to pass parameters to the code with the ~FLAGS~ from a config file using the ~flagfile~ parameter when executing a python script.
We use two configuration files one for training and one for the evaluation. The display configuration file is the same as the evaluation one.
*** Training configuration file
- For the *model*
    - ~model~ the model's name which can be found in ~src/models~. The model's class name must be the name as the module name (e.g. cnn.py and class cnn()).
    - ~save~ the name to use when saving the model.
- For the *data*
    - ~data~ the dataset name. The dataset will be loaded from ~torchvision.datasets~ using only its name.
    - ~dim~ the height and width of the images.
    - ~batchsize~ the batch size to use for the loader.
- For the model's *hyperparameters*
    - ~nb_epoch~ the number of epochs needed for the training.
    - ~in_channels~ the number of inputs channels, it is usually the number of channels of the images (1 or 3).
    - ~out_channels~ the number of output channels, it is usually the number of classes to predict.

- For the *adversarial training*
    - ~adv_train~ boolean if the training must use adversarial examples.
    - ~eps~ the epsilon value used for computing the adversarial example.

*** Evaluation configuration file
- For the *model*
    - ~save~ the name of the save to load.
- For the *data*
    - ~data~ the dataset name. The dataset will be loaded from ~torchvision.datasets~ using only its name.
    - ~batchsize~ the batch size to use for the loader (a smaller batch size can help for ~torch.cuda.OutOfMemoryError~). 
- For the *attacks*   
    - ~attacks~ list of the attacks' name to use.
- For the attacks' *parameters*
    - ~eps~ list of the epsilon values to use for FGSM and PGD attacks.
    - ~norm~ the norm to use for the different attacks (0,1,2, np.inf).
    - ~clip_min~ minimal clip value for the image.
    - ~clip_max~ max clip value for the image either 1/255 for float/int values.
    - ~num_classes~ the number of classes in the dataset
    - ~<attack>_parameters~ a list of the /<attack>/ parameters. 

** The project code

- *models* are defined in ~src/models~. 
- *saved* models are in ~/saves~. 
- *configuration* files are in ~config_files~. 
- *data* are (locally) saved in ~/data~. 
- *training*, *evaluation* and *display* scripts are in ~src/~.
- *attacks* are in ~src/attacks~ they come from [[https://github.com/cleverhans-lab/cleverhans][CleverHans]]
 and [[https://github.com/DSE-MSU/DeepRobust][DeepRobust]]. The attacks from *CleverHans* work out of the box, 
 the attacks from *DeepRobust* have been modified to take in inputs batch of images instead of a single image.