 # Namespace(batch_size=256, data_dir='cifar-data', dataset='MNIST', model='cnn', epochs=30, lr_schedule='cyclic', lr_max=0.2, attack='fgsm', eps=8.0, attack_iters=10, pgd_train_n_iters=10, pgd_alpha_train=2.0, fgsm_alpha=1.25, minibatch_replay=1, weight_decay=0.0005, attack_init='random', fname='plain_cifar10', seed=0, gpu=0, debug=False, half_prec=False, grad_align_cos_lambda=0.0, eval_early_stopped_model=False, eval_iter_freq=200, n_eval_every_k_iter=256, n_layers=1, n_filters_cnn=16, batch_size_eval=256, n_final_eval=-1)
 Epoch,Train loss,Train acc clean,Train acc PGD, Test acc clean,Test acc FGSM,Test acc PGD,Learning Rate, Training time,Time elapsed
 0,2.3470,0.0430,0.0391,0.1211,0.0391,0.0312,0.00,0.00
 1,0.4295,0.8617,0.9531,0.9766,0.9297,0.9258,0.01,0.03
 2,0.1489,0.9539,0.9453,0.9922,0.9531,0.9531,0.03,0.07
 3,0.2326,0.9340,0.9219,0.9727,0.9258,0.9180,0.04,0.11
 4,0.2786,0.9184,0.8867,0.9492,0.8320,0.8047,0.06,0.14
 5,0.4140,0.8823,0.8438,0.9570,0.8516,0.8203,0.07,0.18
 6,0.4265,0.8799,0.8711,0.9492,0.8516,0.8320,0.09,0.21
 6,2.3808,0.1403,0.1016,0.1211,0.1211,0.1211,0.10,0.25
 7,2.3078,0.1036,0.1367,0.1367,0.1367,0.1367,0.11,0.28
 8,2.3183,0.1062,0.1016,0.1211,0.1211,0.1211,0.13,0.31
 9,2.3060,0.1066,0.1172,0.0742,0.0742,0.0742,0.14,0.35
 10,2.3076,0.1058,0.0938,0.1328,0.1328,0.1328,0.16,0.39
 11,2.3070,0.1055,0.1172,0.0898,0.0898,0.0898,0.17,0.42
 12,2.3082,0.1067,0.0938,0.1328,0.1328,0.1328,0.19,0.46
 12,2.3085,0.1041,0.1016,0.1211,0.1211,0.1211,0.20,0.49
 13,2.3139,0.1041,0.0742,0.0547,0.0547,0.0547,0.19,0.53
 14,2.3119,0.1054,0.0977,0.0938,0.0938,0.0938,0.18,0.56
 15,2.3092,0.1028,0.1016,0.1211,0.1211,0.1211,0.17,0.60
 16,2.3079,0.1051,0.0938,0.1328,0.1328,0.1328,0.16,0.64
 17,2.3070,0.1021,0.0664,0.1016,0.1016,0.1016,0.15,0.67
 18,2.3086,0.1010,0.1367,0.1367,0.1367,0.1367,0.14,0.71
 18,2.3077,0.1023,0.1367,0.1367,0.1367,0.1367,0.13,0.75
 19,2.3081,0.1049,0.1172,0.0742,0.0742,0.0742,0.12,0.78
 20,2.3055,0.1072,0.1016,0.1211,0.1211,0.1211,0.11,0.82
 21,2.3043,0.1085,0.1367,0.1367,0.1367,0.1367,0.11,0.86
 22,2.3051,0.1045,0.0938,0.1328,0.1328,0.1328,0.10,0.90
 23,2.3061,0.1023,0.1367,0.1367,0.1367,0.1367,0.09,0.93
 24,2.3030,0.1053,0.0977,0.0938,0.0938,0.0938,0.08,0.97
 24,2.3043,0.1063,0.1367,0.1367,0.1367,0.1367,0.07,1.01
 25,2.3037,0.1075,0.1367,0.1367,0.1367,0.1367,0.06,1.04
 26,2.3036,0.1068,0.1367,0.1367,0.1367,0.1367,0.05,1.08
 27,2.3031,0.1074,0.1367,0.1367,0.1367,0.1367,0.04,1.12
 28,2.3027,0.1095,0.1367,0.1367,0.1367,0.1367,0.03,1.15
 29,2.3023,0.1105,0.1367,0.1367,0.1367,0.1367,0.02,1.19
 30,2.3029,0.1018,0.1367,0.1367,0.1367,0.1367,0.01,1.22
 30,2.3014,0.1129,0.1367,0.1367,0.1367,0.1367,0.00,1.26
