# Model 
--save=basic/cnn_fashion

# Data
--data=MNIST
--batchsize=128

# Adversarial attacks
--attacks=hop_skip_jump_attack

# General parameters
--eps=0.05
# --eps=0,0.00392156862745098,0.00784313725490196,0.011764705882352941,0.01568627450980392,0.0196078431372549,0.023529411764705882,0.027450980392156862,0.03137254901960784,0.03529411764705882,0.0392156862745098,0.043137254901960784,0.047058823529411764,0.050980392156862744,0.054901960784313725,0.058823529411764705,0.06274509803921569,0.06666666666666667,0.07058823529411765,0.07450980392156863,0.0784313725490196
--norm=inf
--clip_min=0
--clip_max=1
--num_classes=10
# fast_gradient_method
# targeted, sanity_checks
--FGSM_params=False,False

# projected_gradient_descent
# eps_iter, nb_iter, targeted, rand_init, rand_minmax, sanity_checks
--PGD_params=0.01,40,False,False,None,False

# carlini_wagner_l2
# targeted, lr, confidence, initial_const, binary_search_steps, max_iter
--CW_params=False,5e-3,0,1e-2,3,100 

# spsa
# nb_iter, targeted, early_stop, lr, delta, spsa_iters, debug, sanity_checks
--SPSA_params=2,False,None,0.01,0.01,1,False,False
# sparse_l1_descent
# eps_iter, iter, targeted, rand_init, clip_grad, grad_sparsity, sanity_checks
--L1d_params=1,20,False,False,False,99,False
# hop_skip_jump_attack
# initial_num_evals, max_num_evals, stepsize_search, iter, gamma, constraint, verbose
--HSJA_params=1,100,geometric_progression,2,1.0,2,False

# deepfool  
# overshoot, iter
--deepfool_params=0.02, 5

# lbfgs #segfault
