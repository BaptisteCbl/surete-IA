

* Installation from fresh environment.
** Create the environment (might be slow):
#+begin_src bash
conda env create --file robust.yml
#+end_src

- If the installation is stuck on ~Solving environment: |~ try:
#+BEGIN_SRC bash
conda config --set channel_priority strict
#+END_SRC
- Revert with:
#+BEGIN_SRC bash
conda config --set channel_priority true
#+END_SRC
** Activate the environment:
#+begin_src bash
conda activate Robust
#+end_src
** Setup the project:
#+begin_src bash
pip install -e .
#+end_src

* Running the  scripts

Running the basic training from adversarial/
#+begin_src bash
python src/pytorch/basic/training.py  --flagfile=config_files/training.cfg
#+end_src

Running the evaluation
#+begin_src bash
python src/pytorch/evaluation.py  --flagfile=config_files/evaluation.cfg
#+end_src

** The configuration files

We use the /abseil/ library to pass parameters to the code with the ~FLAGS~ from a config file using the ~flagfile~ parameter when executing a python script.
We use two configuration files one for training and one for the evaluation. The display configuration file is the same as the evaluation one.
*** Basic training configuration file
- For the *model*
    - ~model~ the model's name which can be found in ~src/models~. The model's class name must be the name as the module name (e.g. cnn.py and class cnn()).
    - ~save~ the name to use when saving the model.
- For the *data*
    - ~data~ the dataset name. The dataset will be loaded from ~torchvision.datasets~ using only its name.
    - ~dim~ the height and width of the images.
    - ~batchsize~ the batch size to use for the loader.
- For the model's *hyperparameters*
    - ~nb_epoch~ the number of epochs needed for the training.
    - ~in_channels~ the number of inputs channels, it is usually the number of channels of the images (1 or 3).
    - ~out_channels~ the number of output channels, it is usually the number of classes to predict.

- For the *adversarial training*
    - ~adv_train~ boolean if the training must use adversarial examples.
    - ~eps~ the epsilon value used for computing the adversarial example.

*** Evaluation configuration file
- For the *model*
    - ~save~ the name of the save to load.
- For the *data*
    - ~data~ the dataset name. The dataset will be loaded from ~torchvision.datasets~ using only its name.
    - ~batchsize~ the batch size to use for the loader (a smaller batch size can help for ~torch.cuda.OutOfMemoryError~). 
- For the *attacks*   
    - ~attacks~ list of the attacks' name to use.
- For the attacks' *parameters*
    - ~eps~ list of the epsilon values to use for FGSM and PGD attacks.
    - ~norm~ the norm to use for the different attacks (0,1,2, np.inf).
    - ~clip_min~ minimal clip value for the image.
    - ~clip_max~ max clip value for the image either 1/255 for float/int values.
    - ~num_classes~ the number of classes in the dataset
    - ~<attack>_parameters~ a list of the /<attack>/ parameters. 

** The project code

- *models* are defined in ~src/pytorch/models~. 
- *saved* models are in ~src/pytorch/saves/<approach>~. 
- *configuration* files are in ~config_files~. 
- *data* are (locally) saved in ~data/~. 
-  *evaluation* and *display* scripts are in ~src/pytorch~.
- *attacks* are in ~src/attacks~ they come from [[https://github.com/cleverhans-lab/cleverhans][CleverHans]]
 and [[https://github.com/DSE-MSU/DeepRobust][DeepRobust]]. The attacks from *CleverHans* work out of the box, 
 the attacks from *DeepRobust* have been modified to take in inputs batch of images instead of a single image.
- There are 3 different approach to train a model: 
    - ~src/pytorch/basic/~ which is "basic" training loop working with all model/data pairs, it can be used to
    perfrom adversarial training
    - ~src/pytorch/fast~ based on [[https://github.com/locuslab/fast_adversarial][fast adversarial]] training approach. There are two folders one to work on MNIST/FashionMnist and one to work on CIFAR10.
    - ~src/pytorch/fast_gradAlign~ based on another [[https://github.com/tml-epfl/understanding-fast-adv-training][fast adversarial]] training approach. It works on MNIST, FashionMNIST and CIFAR10.

** Logs 
In the log file we store the training loss/accuracy/time (and test in the gradAlign) by epoch.
The file are in .csv format using logging. The gnuplot script allows to quicly plot some data.

** Evaluation logs
It contains the logs of the different evaluation.
