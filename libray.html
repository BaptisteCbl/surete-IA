<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-02-09 jeu. 16:58 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Libraries for adversarial examples</title>
<meta name="author" content="Guillaume Coulaud" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Libraries for adversarial examples</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orge4223a0">1. Attacks</a>
<ul>
<li><a href="#org2175b95">1.1. Deep Robust</a></li>
<li><a href="#org8322142">1.2. Cleverhans</a></li>
<li><a href="#orge60d403">1.3. Foolbox</a></li>
</ul>
</li>
<li><a href="#org1f69e04">2. Defense</a>
<ul>
<li><a href="#org8e16b9f">2.1. Deep Robust</a></li>
<li><a href="#orgbb436e3">2.2. Cleverhans</a></li>
</ul>
</li>
<li><a href="#org7c00087">3. More details on Cleverhans</a>
<ul>
<li><a href="#org1e650df">3.1. BIM/PGD</a></li>
<li><a href="#org0b3f5b2">3.2. Carlini</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
<a href="https://github.com/DSE-MSU/DeepRobust">DeepRobust</a>
</p>

<p>
<a href="https://github.com/cleverhans-lab/cleverhans">CleverHans</a>
</p>

<p>
<a href="https://github.com/bethgelab/foolbox">Foolbox</a>
</p>


<div id="outline-container-orge4223a0" class="outline-2">
<h2 id="orge4223a0"><span class="section-number-2">1.</span> Attacks</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org2175b95" class="outline-3">
<h3 id="org2175b95"><span class="section-number-3">1.1.</span> Deep Robust</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>Nattack</li>
<li>universal</li>
<li>YOPO PGD</li>
<li>Carlini (Which one ?)</li>
<li>Deepfool</li>
<li>FGSM</li>
<li>L-BFGS</li>
<li>One pixel</li>
<li>PGD</li>
<li>L2 attack (detail?)</li>
</ul>
</div>
</div>


<div id="outline-container-org8322142" class="outline-3">
<h3 id="org8322142"><span class="section-number-3">1.2.</span> Cleverhans</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>BIM</li>
<li>CW L2</li>
<li>DeepFool</li>
<li>ElasticNet</li>
<li>Fast feature</li>
<li>FGMS</li>
<li>HopSkipJump</li>
<li>LBFGS</li>
<li>MadryEtAl ?</li>
<li>MaxConfidence (against confidence threshold defense)</li>
<li>Momentum iterative method</li>
<li>Saliency map</li>
<li>SPSA</li>
<li>Virtual adversarial method</li>
</ul>
</div>
</div>


<div id="outline-container-orge60d403" class="outline-3">
<h3 id="orge60d403"><span class="section-number-3">1.3.</span> Foolbox</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>BIM \(l_2 + l_\infty\)</li>
<li>PGD \(l_2 + l_\infty\)</li>
<li>FGSM \(l_2 + l_\infty\)</li>
<li>Lots of noise attacks</li>
<li>Inversion (&ldquo;negatives images&rdquo;)</li>
<li>contrast</li>
<li>HopSkipJumpA</li>
<li>C&amp;W \(l_2\)</li>
<li>Newtoon Fool</li>
<li>EAD</li>
<li>DeeFool \(l_2 + l_\infty\)</li>
<li>Boundary attack</li>
<li>Brendel &amp; Bethge \(l_0 + l_1 + l_2 + l_\infty\)</li>
<li>Fast Minimal Norm \(l_0 + l_1 + l_2 + l_\infty\)</li>
<li>Pointwise</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org1f69e04" class="outline-2">
<h2 id="org1f69e04"><span class="section-number-2">2.</span> Defense</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org8e16b9f" class="outline-3">
<h3 id="org8e16b9f"><span class="section-number-3">2.1.</span> Deep Robust</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>LID (detector)</li>
<li>Thermometer encoding</li>
<li>YOPO</li>
<li>Fast defense ?</li>
<li>FGSM training</li>
<li>PGD training</li>
<li>Trade ?</li>
</ul>
</div>
</div>

<div id="outline-container-orgbb436e3" class="outline-3">
<h3 id="orgbb436e3"><span class="section-number-3">2.2.</span> Cleverhans</h3>
<div class="outline-text-3" id="text-2-2">
<p>
not founded
</p>
</div>
</div>
</div>






<div id="outline-container-org7c00087" class="outline-2">
<h2 id="org7c00087"><span class="section-number-2">3.</span> More details on Cleverhans</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org1e650df" class="outline-3">
<h3 id="org1e650df"><span class="section-number-3">3.1.</span> BIM/PGD</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li><b>eps</b>: <i>(optional float)</i> maximum distortion of adversarial example
compared to original input</li>
<li><b>eps_iter</b>: <i>(optional float)</i> step size for each attack iteration</li>
<li><b>nb_iter</b>: <i>(optional int)</i> Number of attack iterations.</li>
<li><b>y</b>: <i>(optional)</i> A tensor with the true labels.</li>
<li><b>y_target</b>: <i>(optional)</i> A tensor with the labels to target. Leave
y_target=None if y is also set. Labels should be
one-hot-encoded.</li>
<li><b>ord</b>: <i>(optional)</i> Order of the norm (mimics Numpy).
Possible values: np.inf, 1 or 2.</li>
<li><b>loss_fn</b>: Loss function that takes (labels, logits) as arguments and returns loss</li>
<li><b>clip_min</b>: <i>(optional float)</i> Minimum input component value</li>
<li><b>clip_max</b>: <i>(optional float)</i> Maximum input component value</li>
<li><b>rand_init</b>: <i>(optional)</i> Start the gradient descent from a point chosen
uniformly at random in the norm ball of radius
rand_init_eps</li>
<li><b>rand_init_eps</b>: <i>(optional float)</i> size of the norm ball from which
the initial starting point is chosen. Defaults to eps</li>
<li><b>clip_grad</b>: <i>(optional bool)</i> Ignore gradient components at positions
where the input is already at the boundary of the domain,
and the update step will get clipped out.</li>
<li><b>sanity_checks</b>: <i>bool</i> Insert tf asserts checking values
(Some tests need to run with no sanity checks because the
 tests intentionally configure the attack strangely)</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #dcaeea;">x</span> = projected_gradient_descent(net, x, FLAGS.eps, <span style="color: #da8548; font-weight: bold;">0.01</span>, <span style="color: #da8548; font-weight: bold;">40</span>, np.inf)
</pre>
</div>
</div>
</div>

<div id="outline-container-org0b3f5b2" class="outline-3">
<h3 id="org0b3f5b2"><span class="section-number-3">3.2.</span> Carlini</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li><b>y</b>: <i>(optional)</i> A tensor with the true labels for an untargeted
attack. If None (and y_target is None) then use the
original labels the classifier assigns.</li>
<li><b>y_target</b>: <i>(optional)</i> A tensor with the target labels for a
targeted attack.</li>
<li><b>confidence</b>: Confidence of adversarial examples: higher produces
examples with larger l2 distortion, but more
strongly classified as adversarial.</li>
<li><b>batch_size</b>: Number of attacks to run simultaneously.</li>
<li><b>learning_rate</b>: The learning rate for the attack algorithm.
Smaller values produce better results but are
slower to converge.</li>
<li><b>binary_search_steps</b>: The number of times we perform binary
search to find the optimal tradeoff-
constant between norm of the purturbation
and confidence of the classification.</li>
<li><b>max_iterations</b>: The maximum number of iterations. Setting this
to a larger value will produce lower distortion
results. Using only a few iterations requires
a larger learning rate, and will produce larger
distortion results.</li>
<li><b>abort_early</b>: If true, allows early aborts if gradient descent
is unable to make progress (i.e., gets stuck in
a local minimum).</li>
<li><b>initial_const</b>: The initial tradeoff-constant to use to tune the
relative importance of size of the perturbation
and confidence of classification.
If binary_search_steps is large, the initial
constant is not important. A smaller value of
this constant gives lower distortion results.</li>
<li><b>clip_min</b>: <i>(optional float)</i> Minimum input component value</li>
<li><b>clip_max</b>: <i>(optional float)</i> Maximum input component value</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Guillaume Coulaud</p>
<p class="date">Created: 2023-02-09 jeu. 16:58</p>
</div>
</body>
</html>